{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from pyproj import CRS\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "#pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train_set.csv')\n",
    "train_labels = pd.read_csv('./train_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.merge(train_labels,on='id')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature in train_df.columns:\n",
    "    print('Feature:', feature, ' missing%:', (np.round(train_df[feature].isnull().mean(),4))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in test_df.columns:\n",
    "    print('Feature:', feature, ' missing%:', (np.round(test_df[feature].isnull().mean(),4))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['funder'] = train_df['funder'].str.lower()\n",
    "train_df['installer'] = train_df['installer'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['funder'] = test_df['funder'].str.lower()\n",
    "test_df['installer'] = test_df['installer'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['funder'] = train_df['funder'].fillna('Unknown') \n",
    "train_df['installer'] = train_df['installer'].fillna('Unknown') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['funder'] = test_df['funder'].fillna('Unknown') \n",
    "test_df['installer'] = test_df['installer'].fillna('Unknown') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.loc[train_df['subvillage'].isnull(),'region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.loc[train_df['subvillage'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite some information(gps_height,year of construction, amount_tsh,population) is not available or not know for the region of Dodoma. Removing data from this region having unknown subvillage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regions -> Districts(lga) -> Divisions -> Ward -> Subvillage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['subvillage'].notna()]\n",
    "\n",
    "train_df['public_meeting'] = train_df['public_meeting'].fillna('Unknown') \n",
    "train_df['scheme_management'] = train_df['scheme_management'].fillna('Unknown') \n",
    "\n",
    "train_df = train_df.loc[:, train_df.columns != 'scheme_name']\n",
    "train_df['permit'] = train_df['permit'].fillna('Unknown') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df['subvillage'].notna()]\n",
    "\n",
    "test_df['public_meeting'] = test_df['public_meeting'].fillna('Unknown') \n",
    "test_df['scheme_management'] = test_df['scheme_management'].fillna('Unknown') \n",
    "\n",
    "test_df = test_df.loc[:, test_df.columns != 'scheme_name']\n",
    "test_df['permit'] = test_df['permit'].fillna('Unknown') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Static Head:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['amount_tsh'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_tsh = (len(train_df[train_df['amount_tsh'] > 9000])/len(train_df))*100\n",
    "print('Only',np.round(high_tsh,4),'% waterpoints have greater than 9000 Total Static Head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.loc[train_df['amount_tsh'] > 9000,'status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date Recorded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['date_recorded'] = pd.to_datetime(train_df['date_recorded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['date_recorded'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['date_recorded'] = pd.to_datetime(test_df['date_recorded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df['funder'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df['funder'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPS Height: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df['gps_height'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['gps_height'] < 0.0,'waterpoint_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative GPS height here represents those waterpoints which have depth like a well, handpump etc. Height for these represents depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_private:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['num_private'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.loc[:, train_df.columns != 'num_private']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.loc[:, test_df.columns != 'num_private']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['basin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region, District and Ward wise all waterpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanzania_regions_url = 'https://raw.githubusercontent.com/thadk/GeoTZ/master/TZA_adm1_mkoaTZ.geojson'\n",
    "regions_json_data = json.loads(requests.get(tanzania_regions_url).text)\n",
    "regions_df = gpd.GeoDataFrame.from_features(regions_json_data, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_df['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_region = train_df.groupby('region')\n",
    "regionwise_waterpoints = pd.DataFrame()\n",
    "regions = []\n",
    "waterpoints = []\n",
    "for name,group in grouped_by_region:\n",
    "    if(name == 'Dar es Salaam'):\n",
    "        name = 'Dar-Es-Salaam'\n",
    "    regions.append(name)\n",
    "    waterpoints.append(len(group))\n",
    "regionwise_waterpoints['region'] = regions\n",
    "regionwise_waterpoints['total_waterpoints'] = waterpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = regions_df.merge(regionwise_waterpoints,left_on='NAME_1',right_on='region',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionwise_waterpoints = merged[['region','total_waterpoints','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionwise_waterpoints = gpd.GeoDataFrame(\n",
    "    regionwise_waterpoints, geometry='geometry')\n",
    "regionwise_waterpoints.crs = CRS.from_epsg(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionwise_waterpoints['geoid'] = regionwise_waterpoints.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = folium.Map([6.3690,34.8888], zoom_start=4)\n",
    "\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data=regionwise_waterpoints,\n",
    "    data=regionwise_waterpoints,\n",
    "    columns=['geoid','total_waterpoints'],\n",
    "    key_on='feature.id',\n",
    "    nan_fill_color='purple',\n",
    "    nan_fill_opacity=0.4,\n",
    "    fill_color='YlGn',\n",
    "    highlight=True\n",
    ").add_to(m)\n",
    "\n",
    "choropleth.geojson.add_child(folium.features.GeoJsonTooltip(\n",
    "        fields=['region','total_waterpoints'],\n",
    "        aliases=['Region','Waterpoints'],\n",
    "        style=('background-color: grey; color: white;'),\n",
    "        localize=True\n",
    "        )\n",
    ")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "district_url = 'https://raw.githubusercontent.com/thadk/GeoTZ/master/TZA_adm2_kiasi84pc%20detail.geojson'\n",
    "districts_json_data = json.loads(requests.get(district_url).text)\n",
    "districts_df = gpd.GeoDataFrame.from_features(districts_json_data, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_districts = train_df.groupby(['region','lga'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districtswise_waterpoints = pd.DataFrame()\n",
    "regions = []\n",
    "districts = []\n",
    "waterpoints = []\n",
    "for name,group in grouped_by_districts:\n",
    "    if(name[0] == 'Dar es Salaam'):\n",
    "        regions.append('Dar-Es-Salaam')\n",
    "    else:\n",
    "        regions.append(name[0])\n",
    "    districts.append(name[1])\n",
    "    waterpoints.append(len(group))\n",
    "districtswise_waterpoints['region'] = regions\n",
    "districtswise_waterpoints['district'] = districts\n",
    "districtswise_waterpoints['total_waterpoints'] = waterpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = districts_df.merge(districtswise_waterpoints,left_on=['NAME_1','NAME_2'],right_on=['region','district'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districtswise_waterpoints = merged[['NAME_1','NAME_2','total_waterpoints','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districtswise_waterpoints = gpd.GeoDataFrame(\n",
    "    districtswise_waterpoints, geometry='geometry')\n",
    "districtswise_waterpoints.crs = CRS.from_epsg(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districtswise_waterpoints['geoid'] = districtswise_waterpoints.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = folium.Map([-6.241,35.679], zoom_start=6)\n",
    "\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data=districtswise_waterpoints,\n",
    "    data=districtswise_waterpoints,\n",
    "    columns=['geoid','total_waterpoints'],\n",
    "    key_on='feature.id',\n",
    "    nan_fill_color='purple',\n",
    "    nan_fill_opacity=0.4,\n",
    "    fill_color='YlOrRd',\n",
    "    highlight=True\n",
    ").add_to(m)\n",
    "\n",
    "choropleth.geojson.add_child(folium.features.GeoJsonTooltip(\n",
    "        fields=['NAME_1','NAME_2','total_waterpoints'],\n",
    "        aliases=['Region','District','Waterpoints'],\n",
    "        style=('background-color: grey; color: white;'),\n",
    "        localize=True\n",
    "        )\n",
    ")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward_url = 'https://raw.githubusercontent.com/thadk/GeoTZ/master/TZA_adm3.geojson'\n",
    "wards_json_data = json.loads(requests.get(ward_url).text)\n",
    "wards_df = gpd.GeoDataFrame.from_features(wards_json_data, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_wards = train_df.groupby(['region','lga','ward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wardswise_waterpoints = pd.DataFrame()\n",
    "regions = []\n",
    "districts = []\n",
    "wards = []\n",
    "waterpoints = []\n",
    "for name,group in grouped_by_wards:\n",
    "    if(name[0] == 'Dar es Salaam'):\n",
    "        regions.append('Dar-Es-Salaam')\n",
    "    else:\n",
    "        regions.append(name[0])\n",
    "    districts.append(name[1])\n",
    "    wards.append(name[2])\n",
    "    waterpoints.append(len(group))\n",
    "wardswise_waterpoints['region'] = regions\n",
    "wardswise_waterpoints['district'] = districts\n",
    "wardswise_waterpoints['ward'] = wards\n",
    "wardswise_waterpoints['total_waterpoints'] = waterpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = wards_df.merge(wardswise_waterpoints,left_on=['NAME_1','NAME_2','NAME_3'],right_on=['region','district','ward'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wardswise_waterpoints = merged[['NAME_1','NAME_2','NAME_3','total_waterpoints','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wardswise_waterpoints = gpd.GeoDataFrame(\n",
    "    wardswise_waterpoints, geometry='geometry')\n",
    "wardswise_waterpoints.crs = CRS.from_epsg(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wardswise_waterpoints['geoid'] = wardswise_waterpoints.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = folium.Map([-6.241,35.679], zoom_start=6)\n",
    "\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data=wardswise_waterpoints,\n",
    "    data=wardswise_waterpoints,\n",
    "    columns=['geoid','total_waterpoints'],\n",
    "    key_on='feature.id',\n",
    "    nan_fill_color='white',\n",
    "    nan_fill_opacity=0.7,\n",
    "    fill_color='OrRd',\n",
    "    fill_opacity=0.9,\n",
    "    line_opacity=0.2,\n",
    "    line_color='white',\n",
    "    highlight=False\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WaterPoints Marker with population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins_url = 'http://geoportal.icpac.net/geoserver/wfs?srsName=EPSG%3A4326&typename=geonode%3Atza_water_areas_dcw&outputFormat=json&version=1.0.0&service=WFS&request=GetFeature'\n",
    "basins_json_data = json.loads(requests.get(basins_url).text)\n",
    "basins_df = gpd.GeoDataFrame.from_features(basins_json_data, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(\n",
    "    location=[-6.241,35.679],\n",
    "    tiles='Stamen Toner',\n",
    "    zoom_start=6,min_zoom=3\n",
    ")\n",
    "\n",
    "marker_cluster = MarkerCluster(\n",
    "    name='waterpoints clustered icons',\n",
    "    overlay=True,\n",
    "    control=False,\n",
    "    icon_create_function=None\n",
    ")\n",
    "size = len(train_df)\n",
    "for k in range(size):\n",
    "    location = train_df['latitude'][k], train_df['longitude'][k]\n",
    "    marker = folium.Marker(location=location)\n",
    "    #popup = 'Region:{}<br>District:{}<br>Ward:{}<br>Sub-village:{}'.format(str(train_df['region'][k]),\n",
    "                                                                           #str(train_df['lga'][k]),str(train_df['ward'][k]),\n",
    "                                                                           #str(train_df['subvillage'][k]))\n",
    "    #folium.Popup(popup).add_to(marker)\n",
    "    marker_cluster.add_child(marker)\n",
    "\n",
    "marker_cluster.add_to(m)\n",
    "\n",
    "#folium.GeoJson(basins_df,name='basins_tanzania').add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.save(os.path.join('results', 'All_waterpoints.html'))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waterpoints divided by the status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(\n",
    "    location=[-6.241,35.679],\n",
    "    tiles='Stamen Toner',\n",
    "    control_scale=True,zoom_start=6,\n",
    "    min_zoom=3\n",
    ")\n",
    "\n",
    "size = len(train_df)\n",
    "\n",
    "for k in range(size):\n",
    "    location = train_df['latitude'][k], train_df['longitude'][k]\n",
    "    status = train_df['status_group'][k]\n",
    "    \n",
    "    if(status == 'functional'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=1000,\n",
    "          color='#00ff00',\n",
    "          fill=True,\n",
    "          fill_color='#00ff00',\n",
    "          #tooltip=\"<div><ul style='color: #444;list-style-type:circle;align-item:left;padding-left:20px;padding-right:20px'>\"+\n",
    "        #\"<li>Subvillage: \"+str(train_df['subvillage'][k])+\"</li>\"+\n",
    "        #\"<li>Accessed by: \"+str(train_df['population'])+\"</li>\"+\n",
    "        #\"</ul></div>\"\n",
    "       ).add_to(m)\n",
    "    elif(status == 'non functional'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=3000,\n",
    "          color='#ff0000',\n",
    "          fill=True,\n",
    "          fill_color='#ff0000',\n",
    "           # tooltip=\"<ul style='color: #444;list-style-type:circle;align-item:left;padding-left:20px;padding-right:20px'>\"+\n",
    "        #\"<li>Subvillage: \"+str(train_df['subvillage'][k])+\"</li>\"+\n",
    "        #\"<li>Accessed by: \"+str(train_df['population'])+\"</li>\"+\n",
    "        #\"</ul>\"\n",
    "       ).add_to(m)\n",
    "    else:\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=2000,\n",
    "          color='#0000ff',\n",
    "          fill=True,\n",
    "          fill_color='#0000ff',\n",
    "           # tooltip=\"<ul style='color: #444;list-style-type:circle;align-item:left;padding-left:20px;padding-right:20px'>\"+\n",
    "        #\"<li>Subvillage: \"+str(train_df['subvillage'][k])+\"</li>\"+\n",
    "        #\"<li>Accessed by: \"+str(train_df['population'])+\"</li>\"+\n",
    "        #\"</ul>\"\n",
    "       ).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#m.save(os.path.join('results', 'waterpoints_by_status.html'))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(\n",
    "    location=[-6.241,35.679],\n",
    "    tiles='Stamen Toner',\n",
    "    control_scale=True,zoom_start=6,\n",
    "    min_zoom=3\n",
    ")\n",
    "\n",
    "size = len(train_df)\n",
    "\n",
    "for k in range(size):\n",
    "    location = train_df['latitude'][k], train_df['longitude'][k]\n",
    "    quantity = train_df['quantity_group'][k]\n",
    "    \n",
    "    if(quantity == 'enough'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=1000,\n",
    "          color='#FFA07A',\n",
    "          fill=True,\n",
    "          fill_color='#FFA07A',\n",
    "          #tooltip=\"<div><ul style='color: #444;list-style-type:circle;align-item:left;padding-left:20px;padding-right:20px'>\"+\n",
    "        #\"<li>Subvillage: \"+str(train_df['subvillage'][k])+\"</li>\"+\n",
    "        #\"<li>Accessed by: \"+str(train_df['population'])+\"</li>\"+\n",
    "        #\"</ul></div>\"\n",
    "       ).add_to(m)\n",
    "    elif(quantity == 'seasonal'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=2000,\n",
    "          color='#CD5C5C',\n",
    "          fill=True,\n",
    "          fill_color='#CD5C5C',\n",
    "       ).add_to(m)\n",
    "    elif(quantity == 'dry'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=4000,\n",
    "          color='#FF0000',\n",
    "          fill=True,\n",
    "          fill_color='#FF0000',\n",
    "       ).add_to(m)\n",
    "    elif(quantity == 'insufficient'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=5000,\n",
    "          color='#8B0000',\n",
    "          fill=True,\n",
    "          fill_color='#8B0000',\n",
    "       ).add_to(m)\n",
    "    else:\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=3000,\n",
    "          color='#1E90FF',\n",
    "          fill=True,\n",
    "          fill_color='#1E90FF',\n",
    "       ).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#m.save(os.path.join('results', 'waterpoints_by_quantity.html'))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantity of water and status of the waterpoints are highly related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(\n",
    "    location=[-6.241,35.679],\n",
    "    tiles='Stamen Toner',\n",
    "    control_scale=True,zoom_start=6,\n",
    "    min_zoom=3\n",
    ")\n",
    "\n",
    "size = len(train_df)\n",
    "\n",
    "for k in range(size):\n",
    "    location = train_df['latitude'][k], train_df['longitude'][k]\n",
    "    quality = train_df['quality_group'][k]\n",
    "    \n",
    "    if(quality == 'good'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=1000,\n",
    "          color='#87CEFA',\n",
    "          fill=True,\n",
    "          fill_color='#87CEFA',\n",
    "          #tooltip=\"<div><ul style='color: #444;list-style-type:circle;align-item:left;padding-left:20px;padding-right:20px'>\"+\n",
    "        #\"<li>Subvillage: \"+str(train_df['subvillage'][k])+\"</li>\"+\n",
    "        #\"<li>Accessed by: \"+str(train_df['population'])+\"</li>\"+\n",
    "        #\"</ul></div>\"\n",
    "       ).add_to(m)\n",
    "    elif(quality == 'salty'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=3000,\n",
    "          color='#8A2BE2',\n",
    "          fill=True,\n",
    "          fill_color='#8A2BE2',\n",
    "       ).add_to(m)\n",
    "    elif(quality == 'milky'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=4000,\n",
    "          color='#4682B4',\n",
    "          fill=True,\n",
    "          fill_color='#4682B4',\n",
    "       ).add_to(m)\n",
    "    elif(quality == 'colored'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=5000,\n",
    "          color='#0000FF',\n",
    "          fill=True,\n",
    "          fill_color='#0000FF',\n",
    "       ).add_to(m)\n",
    "    elif(quality == 'fluoride'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=6000,\n",
    "          color='#00008B',\n",
    "          fill=True,\n",
    "          fill_color='#00008B',\n",
    "       ).add_to(m)\n",
    "    else:\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=2000,\n",
    "          color='#32CD32',\n",
    "          fill=True,\n",
    "          fill_color='#32CD32',\n",
    "       ).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#m.save(os.path.join('results', 'waterpoints_by_quality.html'))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m = folium.Map(\n",
    "    location=[-6.241,35.679],\n",
    "    tiles='Stamen Toner',\n",
    "    control_scale=True,zoom_start=6,\n",
    "    min_zoom=3\n",
    ")\n",
    "\n",
    "size = len(train_df)\n",
    "\n",
    "for k in range(size):\n",
    "    location = train_df['latitude'][k], train_df['longitude'][k]\n",
    "    quantity = train_df['extraction_type'][k]\n",
    "    \n",
    "    if(quantity == 'enough'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=1000,\n",
    "          color='#FFA07A',\n",
    "          fill=True,\n",
    "          fill_color='#FFA07A',\n",
    "          #tooltip=\"<div><ul style='color: #444;list-style-type:circle;align-item:left;padding-left:20px;padding-right:20px'>\"+\n",
    "        #\"<li>Subvillage: \"+str(train_df['subvillage'][k])+\"</li>\"+\n",
    "        #\"<li>Accessed by: \"+str(train_df['population'])+\"</li>\"+\n",
    "        #\"</ul></div>\"\n",
    "       ).add_to(m)\n",
    "    elif(quantity == 'seasonal'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=2000,\n",
    "          color='#CD5C5C',\n",
    "          fill=True,\n",
    "          fill_color='#CD5C5C',\n",
    "       ).add_to(m)\n",
    "    elif(quantity == 'dry'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=4000,\n",
    "          color='#FF0000',\n",
    "          fill=True,\n",
    "          fill_color='#FF0000',\n",
    "       ).add_to(m)\n",
    "    elif(quantity == 'insufficient'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=5000,\n",
    "          color='#8B0000',\n",
    "          fill=True,\n",
    "          fill_color='#8B0000',\n",
    "       ).add_to(m)\n",
    "    else:\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=3000,\n",
    "          color='#1E90FF',\n",
    "          fill=True,\n",
    "          fill_color='#1E90FF',\n",
    "       ).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(\n",
    "    location=[-6.241,35.679],\n",
    "    tiles='Stamen Toner',\n",
    "    control_scale=True,zoom_start=6,\n",
    "    min_zoom=3\n",
    ")\n",
    "\n",
    "size = len(train_df)\n",
    "\n",
    "for k in range(size):\n",
    "    location = train_df['latitude'][k], train_df['longitude'][k]\n",
    "    quantity = train_df['quantity_group'][k]\n",
    "    \n",
    "    if(quantity == 'enough'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=1000,\n",
    "          color='#FFA07A',\n",
    "          fill=True,\n",
    "          fill_color='#FFA07A',\n",
    "          #tooltip=\"<div><ul style='color: #444;list-style-type:circle;align-item:left;padding-left:20px;padding-right:20px'>\"+\n",
    "        #\"<li>Subvillage: \"+str(train_df['subvillage'][k])+\"</li>\"+\n",
    "        #\"<li>Accessed by: \"+str(train_df['population'])+\"</li>\"+\n",
    "        #\"</ul></div>\"\n",
    "       ).add_to(m)\n",
    "    elif(quantity == 'seasonal'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=2000,\n",
    "          color='#CD5C5C',\n",
    "          fill=True,\n",
    "          fill_color='#CD5C5C',\n",
    "       ).add_to(m)\n",
    "    elif(quantity == 'dry'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=4000,\n",
    "          color='#FF0000',\n",
    "          fill=True,\n",
    "          fill_color='#FF0000',\n",
    "       ).add_to(m)\n",
    "    elif(quantity == 'insufficient'):\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=5000,\n",
    "          color='#8B0000',\n",
    "          fill=True,\n",
    "          fill_color='#8B0000',\n",
    "       ).add_to(m)\n",
    "    else:\n",
    "        folium.Circle(\n",
    "          location=location,\n",
    "          radius=3000,\n",
    "          color='#1E90FF',\n",
    "          fill=True,\n",
    "          fill_color='#1E90FF',\n",
    "       ).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- A waterpoints longetivity could be taken as a new feature. Longetivity = construction year - date recorded(if not functional or needs repair)\n",
    "--- Population can be divided into bins, same for amount_tsh and gps_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yearwise_df = train_df.groupby('construction_year')\n",
    "year = []\n",
    "waterpoints_number =  []\n",
    "yearwise_waterpoints = pd.DataFrame()\n",
    "for name,group in yearwise_df:\n",
    "    year.append(name)\n",
    "    waterpoints_number.append(len(group))\n",
    "yearwise_waterpoints['year'] = year\n",
    "yearwise_waterpoints['waterpoints_number'] = waterpoints_number\n",
    "yearwise_waterpoints = yearwise_waterpoints[yearwise_waterpoints['year']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=yearwise_waterpoints['year'],y=yearwise_waterpoints['waterpoints_number'],\n",
    "              mode='lines+markers',name=\"Waterpoints made every year\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 20,000 waterpoints have no recorded construction year. Out of the rest, maximum were made in 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df,x='amount_tsh',nbins=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df, x=\"permit\", color=\"status_group\", title=\"Waterpoints status by their Permit \")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df, y=\"extraction_type\", title=\"Extraction Type\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = train_df['status_group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(status)):\n",
    "    col = 'extraction_type_group'\n",
    "    stat = status[i]\n",
    "    temp = train_df[train_df['status_group'] == stat]\n",
    "    names = temp[col].unique()\n",
    "    values = []\n",
    "    for i in range(0,len(names)):\n",
    "        values.append(len(temp[temp[col] == names[i]]))\n",
    "    title = 'Extraction type in '+stat + ' waterpoints'\n",
    "    fig = px.pie(values=values, names=names, title=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df, x=\"payment\", title=\"Waterpoints status by payment\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(status)):\n",
    "    col = 'payment_type'\n",
    "    stat = status[i]\n",
    "    temp = train_df[train_df['status_group'] == stat]\n",
    "    names = temp[col].unique()\n",
    "    values = []\n",
    "    for i in range(0,len(names)):\n",
    "        values.append(len(temp[temp[col] == names[i]]))\n",
    "    title = 'Payment type in '+stat + ' waterpoints'\n",
    "    fig = px.pie(values=values, names=names, title=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df, x=\"water_quality\",title=\"Status by Water Quality\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(status)):\n",
    "    col = 'quality_group'\n",
    "    stat = status[i]\n",
    "    temp = train_df[train_df['status_group'] == stat]\n",
    "    names = temp[col].unique()\n",
    "    values = []\n",
    "    for i in range(0,len(names)):\n",
    "        values.append(len(temp[temp[col] == names[i]]))\n",
    "    title = 'Water quality type in '+stat + ' waterpoints'\n",
    "    fig = px.pie(values=values, names=names, title=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df, x=\"quantity\",title=\"Status by Quantity\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(status)):\n",
    "    col = 'quantity_group'\n",
    "    stat = status[i]\n",
    "    temp = train_df[train_df['status_group'] == stat]\n",
    "    names = temp[col].unique()\n",
    "    values = []\n",
    "    for i in range(0,len(names)):\n",
    "        values.append(len(temp[temp[col] == names[i]]))\n",
    "    title = 'Water quantity type in '+stat + ' waterpoints'\n",
    "    fig = px.pie(values=values, names=names, title=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df, x=\"source\",title=\"Status by Source\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(status)):\n",
    "    col = 'source_type'\n",
    "    stat = status[i]\n",
    "    temp = train_df[train_df['status_group'] == stat]\n",
    "    names = temp[col].unique()\n",
    "    values = []\n",
    "    for i in range(0,len(names)):\n",
    "        values.append(len(temp[temp[col] == names[i]]))\n",
    "    title = 'Water source type in '+stat + ' waterpoints'\n",
    "    fig = px.pie(values=values, names=names, title=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(status)):\n",
    "    col = 'source_class'\n",
    "    stat = status[i]\n",
    "    temp = train_df[train_df['status_group'] == stat]\n",
    "    names = temp[col].unique()\n",
    "    values = []\n",
    "    for i in range(0,len(names)):\n",
    "        values.append(len(temp[temp[col] == names[i]]))\n",
    "    title = 'Water source class in '+stat + ' waterpoints'\n",
    "    fig = px.pie(values=values, names=names, title=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df, x=\"waterpoint_type\",title=\"Status by Waterpoint Type\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(status)):\n",
    "    col = 'waterpoint_type_group'\n",
    "    stat = status[i]\n",
    "    temp = train_df[train_df['status_group'] == stat]\n",
    "    names = temp[col].unique()\n",
    "    values = []\n",
    "    for i in range(0,len(names)):\n",
    "        values.append(len(temp[temp[col] == names[i]]))\n",
    "    title = 'Water source type in '+stat + ' waterpoints'\n",
    "    fig = px.pie(values=values, names=names, title=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df, x=\"management\",title=\"Status by management\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(status)):\n",
    "    col = 'management_group'\n",
    "    stat = status[i]\n",
    "    temp = train_df[train_df['status_group'] == stat]\n",
    "    names = temp[col].unique()\n",
    "    values = []\n",
    "    for i in range(0,len(names)):\n",
    "        values.append(len(temp[temp[col] == names[i]]))\n",
    "    title = 'Water management type in '+stat + ' waterpoints'\n",
    "    fig = px.pie(values=values, names=names, title=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same charts for quantity and quantity group,source,source_type,source_class,waterpoint_type,waterpoint_type_group,\n",
    "#management,management_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = train_df[['population','amount_tsh']].sort_values('population',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "values = []\n",
    "names=[]\n",
    "\n",
    "for i in range(0,len(status)):\n",
    "    col = 'population'\n",
    "    stat = status[i]\n",
    "    temp = train_df[train_df['status_group'] == stat]\n",
    "   \n",
    "    names.append(stat)\n",
    "    values.append(temp[col].sum())\n",
    "    \n",
    "title = 'Population served by different waterpoints'\n",
    "fig = px.pie(values=values, names=names, title=title)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(status)):\n",
    "    col = 'region'\n",
    "    stat = status[i]\n",
    "    temp = train_df[train_df['status_group'] == stat]\n",
    "    names = temp[col].unique()\n",
    "    values = []\n",
    "    for i in range(0,len(names)):\n",
    "        values.append(len(temp[temp[col] == names[i]]))\n",
    "    title = 'Region wise '+ stat + ' waterpoints'\n",
    "    fig = px.pie(values=values, names=names, title=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['basin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins_url = 'http://geoportal.icpac.net/geoserver/wfs?srsName=EPSG%3A4326&typename=geonode%3Atza_water_areas_dcw&outputFormat=json&version=1.0.0&service=WFS&request=GetFeature'\n",
    "basins_json_data = json.loads(requests.get(basins_url).text)\n",
    "basins_df = gpd.GeoDataFrame.from_features(basins_json_data, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(\n",
    "    location=[-6.241,35.679],\n",
    "    tiles='Cartodb Positron',\n",
    "    control_scale=True,zoom_start=6,\n",
    "    min_zoom=3,\n",
    "    max_zoom=7)\n",
    "\n",
    "\n",
    "folium.GeoJson(basins_df,\n",
    "               name='basins_tanzania').add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['funder'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['installer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df['wpt_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.loc[:, train_df.columns != 'funder']\n",
    "train_df = train_df.loc[:, train_df.columns != 'installer']\n",
    "train_df = train_df.loc[:, train_df.columns != 'wpt_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.loc[:, test_df.columns != 'funder']\n",
    "test_df = test_df.loc[:, test_df.columns != 'installer']\n",
    "test_df = test_df.loc[:, test_df.columns != 'wpt_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['basin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['basin']= label_encoder.fit_transform(train_df['basin']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['basin']= label_encoder.fit_transform(test_df['basin']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df['region'].unique()) == len(train_df['region_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['region_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df['district_code'].unique()) == len(train_df['lga'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['district_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['lga','district_code','region_code','region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lga']= label_encoder.fit_transform(train_df['lga']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['lga']= label_encoder.fit_transform(test_df['lga']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['region_code','region']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['region']= label_encoder.fit_transform(train_df['region']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['region']= label_encoder.fit_transform(test_df['region']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ward'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_df['ward'].value_counts()\n",
    "ward_data = pd.DataFrame()\n",
    "ward_data['ward'] = temp.index\n",
    "ward_data['count'] = temp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_wards = ward_data.loc[ward_data['count'] <= 10,'ward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_wards.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = train_df.copy()\n",
    "other_wards = other_wards.to_numpy()\n",
    "def group_other_wards(ward):\n",
    "    if ward in other_wards:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return ward\n",
    "    \n",
    "train_df1['ward'] = train_df['ward'].apply(lambda x:group_other_wards(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test_df['ward'].value_counts()\n",
    "ward_data1 = pd.DataFrame()\n",
    "ward_data1['ward'] = temp.index\n",
    "ward_data1['count'] = temp.values\n",
    "\n",
    "other_wards1 = ward_data1.loc[ward_data1['count'] <= 10,'ward']\n",
    "\n",
    "other_wards1.reset_index(drop=True)\n",
    "\n",
    "test_df1 = test_df.copy()\n",
    "other_wards1 = other_wards1.to_numpy()\n",
    "def group_other_wards(ward):\n",
    "    if ward in other_wards1:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return ward\n",
    "    \n",
    "test_df1['ward'] = test_df['ward'].apply(lambda x:group_other_wards(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['ward'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['subvillage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_df['subvillage'].value_counts()\n",
    "village_data = pd.DataFrame()\n",
    "village_data['subvillage'] = temp.index\n",
    "village_data['count'] = temp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "village_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "village_data[village_data['count'] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "other_villages = village_data.loc[village_data['count'] <= 10,'subvillage']\n",
    "other_villages.reset_index(drop=True)\n",
    "\n",
    "other_villages = other_villages.to_numpy()\n",
    "def group_other_villages(village):\n",
    "    if village in other_villages:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return village\n",
    "    \n",
    "train_df1['subvillage'] = train_df1['subvillage'].apply(lambda x:group_other_villages(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['subvillage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test_df['subvillage'].value_counts()\n",
    "village_data1 = pd.DataFrame()\n",
    "village_data1['subvillage'] = temp.index\n",
    "village_data1['count'] = temp.values\n",
    "\n",
    "\n",
    "other_villages1 = village_data1.loc[village_data1['count'] <= 10,'subvillage']\n",
    "other_villages1.reset_index(drop=True)\n",
    "\n",
    "other_villages1 = other_villages1.to_numpy()\n",
    "def group_other_villages(village):\n",
    "    if village in other_villages1:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return village\n",
    "    \n",
    "test_df1['subvillage'] = test_df1['subvillage'].apply(lambda x:group_other_villages(x),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['ward']= label_encoder.fit_transform(train_df1['ward']) \n",
    "train_df1['subvillage']= label_encoder.fit_transform(train_df1['subvillage']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['ward']= label_encoder.fit_transform(test_df1['ward']) \n",
    "test_df1['subvillage']= label_encoder.fit_transform(test_df1['subvillage']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['public_meeting'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['permit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_bool(val):\n",
    "    if val == 'Unknown':\n",
    "        return -1\n",
    "    elif val == False:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "train_df1['public_meeting'] = train_df1['public_meeting'].apply(convert_to_bool)\n",
    "train_df1['permit'] = train_df1['permit'].apply(convert_to_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['public_meeting'] = test_df1['public_meeting'].apply(convert_to_bool)\n",
    "test_df1['permit'] = test_df1['permit'].apply(convert_to_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['scheme_management'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['extraction_type']= label_encoder.fit_transform(train_df1['extraction_type']) \n",
    "train_df1['extraction_type_group']= label_encoder.fit_transform(train_df1['extraction_type_group']) \n",
    "train_df1['extraction_type_class']= label_encoder.fit_transform(train_df1['extraction_type_class']) \n",
    "train_df1['scheme_management']= label_encoder.fit_transform(train_df1['scheme_management']) \n",
    "train_df1['management']= label_encoder.fit_transform(train_df1['management']) \n",
    "train_df1['management_group']= label_encoder.fit_transform(train_df1['management_group']) \n",
    "train_df1['payment']= label_encoder.fit_transform(train_df1['payment']) \n",
    "train_df1['payment_type']= label_encoder.fit_transform(train_df1['payment_type']) \n",
    "train_df1['water_quality']= label_encoder.fit_transform(train_df1['water_quality']) \n",
    "train_df1['quality_group']= label_encoder.fit_transform(train_df1['quality_group']) \n",
    "train_df1['quantity']= label_encoder.fit_transform(train_df1['quantity']) \n",
    "train_df1['quantity_group']= label_encoder.fit_transform(train_df1['quantity_group']) \n",
    "train_df1['source']= label_encoder.fit_transform(train_df1['source']) \n",
    "train_df1['source_type']= label_encoder.fit_transform(train_df1['source_type']) \n",
    "train_df1['source_class']= label_encoder.fit_transform(train_df1['source_class']) \n",
    "train_df1['waterpoint_type']= label_encoder.fit_transform(train_df1['waterpoint_type']) \n",
    "train_df1['waterpoint_type_group']= label_encoder.fit_transform(train_df1['waterpoint_type_group']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['extraction_type']= label_encoder.fit_transform(test_df1['extraction_type']) \n",
    "test_df1['extraction_type_group']= label_encoder.fit_transform(test_df1['extraction_type_group']) \n",
    "test_df1['extraction_type_class']= label_encoder.fit_transform(test_df1['extraction_type_class']) \n",
    "test_df1['scheme_management']= label_encoder.fit_transform(test_df1['scheme_management']) \n",
    "test_df1['management']= label_encoder.fit_transform(test_df1['management']) \n",
    "test_df1['management_group']= label_encoder.fit_transform(test_df1['management_group']) \n",
    "test_df1['payment']= label_encoder.fit_transform(test_df1['payment']) \n",
    "test_df1['payment_type']= label_encoder.fit_transform(test_df1['payment_type']) \n",
    "test_df1['water_quality']= label_encoder.fit_transform(test_df1['water_quality']) \n",
    "test_df1['quality_group']= label_encoder.fit_transform(test_df1['quality_group']) \n",
    "test_df1['quantity']= label_encoder.fit_transform(test_df1['quantity']) \n",
    "test_df1['quantity_group']= label_encoder.fit_transform(test_df1['quantity_group']) \n",
    "test_df1['source']= label_encoder.fit_transform(test_df1['source']) \n",
    "test_df1['source_type']= label_encoder.fit_transform(test_df1['source_type']) \n",
    "test_df1['source_class']= label_encoder.fit_transform(test_df1['source_class']) \n",
    "test_df1['waterpoint_type']= label_encoder.fit_transform(test_df1['waterpoint_type']) \n",
    "test_df1['waterpoint_type_group']= label_encoder.fit_transform(test_df1['waterpoint_type_group']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def longetivity_feature(row):\n",
    "    if (row['construction_year'] == 0):\n",
    "        return -1\n",
    "    else:\n",
    "        val = row['date_recorded'].year - row['construction_year']\n",
    "        return val\n",
    "train_df1['longetivity'] = train_df1.apply(lambda row:longetivity_feature(row),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['longetivity'] = test_df1.apply(lambda row:longetivity_feature(row),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we can calculate bins for amount_tsh and gps_height. For now, only normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['amount_tsh'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = range(0,350001,50)\n",
    "labels = range(1,7001)\n",
    "train_df1['amount_tsh'] = train_df1['amount_tsh'].astype(int)\n",
    "train_df1['amount_tsh_binned'] = pd.cut(train_df1['amount_tsh'], bins=bins, labels=labels)\n",
    "test_df1['amount_tsh'] = test_df1['amount_tsh'].astype(int)\n",
    "test_df1['amount_tsh_binned'] = pd.cut(test_df1['amount_tsh'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['amount_tsh_binned'] = train_df1['amount_tsh_binned'].astype(float)\n",
    "train_df1['amount_tsh_binned'] = train_df1['amount_tsh_binned'].fillna(0)\n",
    "train_df1['amount_tsh_binned'] = train_df1['amount_tsh_binned'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['amount_tsh_binned'] = test_df1['amount_tsh_binned'].astype(float)\n",
    "test_df1['amount_tsh_binned'] = test_df1['amount_tsh_binned'].fillna(0)\n",
    "test_df1['amount_tsh_binned'] = test_df1['amount_tsh_binned'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['gps_height'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = range(-91,2790,30)\n",
    "labels = range(1,97)\n",
    "train_df1['gps_height'] = train_df1['gps_height'].astype(int)\n",
    "train_df1['gps_height_binned'] = pd.cut(train_df1['gps_height'], bins=bins, labels=labels)\n",
    "test_df1['gps_height'] = test_df1['gps_height'].astype(int)\n",
    "test_df1['gps_height_binned'] = pd.cut(test_df1['gps_height'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1[train_df1['gps_height'] == -90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['gps_height_binned'] = train_df1['gps_height_binned'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['gps_height_binned'] = test_df1['gps_height_binned'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Geospatial Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be **9** clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kms_per_radian = 6371.0088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_reduce(df,epsilon):\n",
    "    coords = df[['latitude', 'longitude']].values\n",
    "    dbscan = DBSCAN(eps=epsilon,min_samples=1,algorithm='ball_tree',metric='haversine').fit(np.radians(coords))\n",
    "    labels = dbscan.labels_\n",
    "    n_clusters = len(set(labels))\n",
    "    print('number of clusters:',n_clusters)\n",
    "    clusters = [coords[labels == n] for  n in range(n_clusters)]\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 5 / kms_per_radian\n",
    "clusters = dbscan_reduce(train_df1,epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 5 / kms_per_radian\n",
    "clusters_test = dbscan_reduce(test_df1,epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(data):\n",
    "    for i in range(0,len(clusters)):\n",
    "        for j in range(0,len(clusters[i])):\n",
    "            data.loc[(data['latitude'] == clusters[i][j][0]) & (data['longitude'] == clusters[i][j][1]),'location_cluster'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clusters(train_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clusters(test_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['amount_tsh_binned','gps_height_binned','basin','subvillage','region','lga','ward','population','public_meeting',\n",
    "           'scheme_management','permit','extraction_type','extraction_type_group','extraction_type_class','management',\n",
    "           'management_group','payment','payment_type','water_quality','quality_group','quantity','quantity_group',\n",
    "           'source','source_type','source_class','waterpoint_type','waterpoint_type_group','longetivity','location_cluster']\n",
    "X = train_df1[columns]\n",
    "y = train_df1['status_group']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_df1[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = MinMaxScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = scaled.transform(X_train)\n",
    "X_test1 = scaled.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train1, index=X_train.index, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test1, index=X_test.index, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= label_encoder.fit_transform(y_train) \n",
    "y_test= label_encoder.fit_transform(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = MinMaxScaler().fit(test_data)\n",
    "test_data1 = scaled.transform(test_data)\n",
    "test_scaled = pd.DataFrame(test_data1, index=test_data.index, columns=test_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non-functional -2, functional - 0, needs repair- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_rate(y_pred):\n",
    "    count = 0\n",
    "    for i in range(0,len(y_pred)):\n",
    "        if y_pred[i] == y_test[i]:\n",
    "            count = count + 1\n",
    "    rate = count / len(y_test)\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_size = list(range(3,15))\n",
    "n_neighbors = list(range(1,12))\n",
    "\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model_knn = GridSearchCV(model, hyperparameters, cv=10,n_jobs=-1)\n",
    "best_model_knn = model_knn.fit(X_train,y_train)\n",
    "\n",
    "print('Best leaf_size:', best_model_knn.best_estimator_.get_params()['leaf_size'])\n",
    "#print('Best p:', best_model_knn.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model_knn.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn1 = KNeighborsClassifier(leaf_size=5,n_neighbors = 3,p=1)\n",
    "model_knn1.fit(X_train,y_train)\n",
    "y_pred = model_knn1.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred)\n",
    "print('Classification rate',classification_rate(y_pred))\n",
    "print('Accuracy:',accuracy_knn)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(verbosity=3,objective='multi:softmax')\n",
    "parameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "               \"max_depth\": [2, 4, 7, 10],\n",
    "               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "               \"n_estimators\": [250, 500, 1000, 2000, 3000]}\n",
    "xgb_rscv = RandomizedSearchCV(xgb_clf,param_distributions=parameters,cv = 7, verbose = 3, random_state = 40,scoring='f1_micro')\n",
    "model_xgboost = xgb_rscv.fit(X_train, y_train)\n",
    "params = model_xgboost.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBClassifier(colsample_bylevel= 1,colsample_bynode= 1, colsample_bytree= 0.8, gamma= 1,\n",
    "                              learning_rate= 0.1,max_depth= 4,n_estimators= 3000,subsample= 0.7,objective='multi:softprob')\n",
    "model_xgb.fit(X_train,y_train)\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print('Classification rate',classification_rate(y_pred_xgb))\n",
    "print('Accuracy score:',accuracy_xgb)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model_xgb.predict(test_df[columns])\n",
    "test_pred_df = pd.DataFrame()\n",
    "test_pred_df['id'] = test_df1['id']\n",
    "test_pred_df['status_group'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_importance(model_xgb)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forrest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor(random_state = 42)\n",
    "# params_rg = {'bootstrap': [True, False],\n",
    "#  'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "#  'max_features': ['auto', 'sqrt'],\n",
    "#  'min_samples_leaf': [1, 2, 4],\n",
    "#  'min_samples_split': [2, 5, 10],\n",
    "#  'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "# xgb_rscv = RandomizedSearchCV(xgb_clf,param_distributions=parameters,cv = 7, random_state = 40,scoring='f1_micro',n_jobs=-1)\n",
    "# model_xgboost = xgb_rscv.fit(X_train, y_train)\n",
    "# params = model_xgboost.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(random_state = 1, max_depth = 15, n_estimators = 2000, min_samples_split = 2, min_samples_leaf = 1)\n",
    "                                   \n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print('Classification rate',classification_rate(y_pred_rf))\n",
    "print('Accuracy score:',accuracy_rf)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo_env]",
   "language": "python",
   "name": "conda-env-geo_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
